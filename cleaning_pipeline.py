import pandas as pd
import ast
from prefect import flow, task
from prefect.logging import get_logger

logger = get_logger("data_pipeline")


@task
def load_data():
    """üì• Charge les donn√©es depuis les fichiers JSON et CSV"""
    logger.info("üì• Chargement des donn√©es...")

    df_bpi = pd.read_json(r'sources/bpifrance_startups_data2.json')
    df_tech = pd.read_json(r"sources/tech_fest_data.json")
    df_maddy = pd.read_json(r"sources/entreprises_data - maddyness.json")
    df_CESFR = pd.read_csv(r"sources/exposantsFRCES2025.csv")
    df_mina = pd.read_csv(r'sources/societes_minalogic.csv')
    df_viva = pd.read_csv(r'sources/partners_viva_tech.csv')
    df_siren = pd.read_csv(r'sources/enriched_company_data.csv')

    logger.info("‚úÖ Donn√©es charg√©es avec succ√®s.")
    return df_bpi, df_tech, df_maddy, df_CESFR, df_mina, df_viva, df_siren


@task
def unpack_minalogic(df_mina):
    """üîç D√©balle les colonnes 'contact' et 'infos' dans df_mina"""
    logger.info("üîÑ D√©ballage des donn√©es Minalogic...")

    def to_dict(x):
        if isinstance(x, str):
            try:
                return ast.literal_eval(x)
            except:
                return None
        return x

    df_mina['contact'] = df_mina['contact'].apply(to_dict)
    df_mina['infos'] = df_mina['infos'].apply(to_dict)

    df_mina['Adresse'] = df_mina['contact'].apply(lambda d: d.get('Adresse') if isinstance(d, dict) else None)
    df_mina['Contact'] = df_mina['contact'].apply(lambda d: d.get('Contact') if isinstance(d, dict) else None)
    df_mina['Date de cr√©ation'] = df_mina['infos'].apply(lambda d: d.get('Date de cr√©ation') if isinstance(d, dict) else None)
    df_mina['mots_cles_a'] = df_mina['infos'].apply(lambda d: d.get('Th√©matiques') if isinstance(d, dict) else None)
    df_mina['March√©'] = df_mina['infos'].apply(lambda d: d.get('March√©s') if isinstance(d, dict) else None)
    df_mina["Date d'adh√©sion"] = df_mina['infos'].apply(lambda d: d.get("Date d'adh√©sion") if isinstance(d, dict) else None)
    df_mina["Type d'organisme"] = df_mina['infos'].apply(lambda d: d.get("Type d'organisme") if isinstance(d, dict) else None)

    logger.info("‚úÖ D√©ballage termin√©.")
    return df_mina


@task
def clean_data(df_bpi, df_tech, df_maddy, df_CESFR, df_mina, df_viva, df_siren):
    """üßº Nettoie et normalise les colonnes de tous les DataFrames"""
    logger.info("üîÑ Nettoyage et normalisation des donn√©es...")

    # ‚úÖ Liste des renommages (liste de tuples)
    rename_mappings = [
        (df_bpi, {'name': 'nom', 'hashtags': 'mots_cles_b', 'website': 'site_web'}),
        (df_CESFR, {'Nom': 'nom', 'Description': 'description', 'Cat√©gories': 'mots_cles_y', 
                    'Website': 'site_web_z', 'Adresse': 'adresse_z', 'Logo': 'logo'}),
        (df_maddy, {'Nom': 'nom', 'Description': 'description', 'Site internet': 'site_web', 
                    'Logo': 'logo', 'Hashtags': 'mots_cles_z'}),
        (df_mina, {'name': 'nom', 'Logo': 'logo'}),
        (df_viva, {'name': 'nom', 'website': 'site_web_u', 'Logo': 'logo'})
    ]

    # ‚úÖ Appliquer les renommages
    for df, rename_map in rename_mappings:
        df.rename(columns=rename_map, inplace=True)

    # ‚úÖ Suppression des colonnes inutiles
    def safe_drop(df, cols):
        existing_cols = [col for col in cols if col in df.columns]
        df.drop(columns=existing_cols, inplace=True, errors='ignore')

    safe_drop(df_tech, ['social_links'])
    safe_drop(df_bpi, ['total_funding'])
    safe_drop(df_CESFR, ['Lien'])
    safe_drop(df_maddy, ['Si√®ge', 'Date de cr√©ation'])
    safe_drop(df_mina, ['url', "Date d'adh√©sion", "contact", "infos"])
    safe_drop(df_viva, ["link", "looking_for", "development_level"])
    safe_drop(df_siren, ["√âtat administratif", "Cat√©gorie entreprise", "Denomination usuelle"])

    # ‚úÖ Mise en majuscules
    for df in [df_bpi, df_tech, df_maddy, df_CESFR, df_mina, df_viva]:
        if 'nom' in df.columns:
            df['nom'] = df['nom'].str.upper()

    logger.info("‚úÖ Nettoyage termin√©.")
    return df_bpi, df_tech, df_maddy, df_CESFR, df_mina, df_viva, df_siren


@task
def merge_data(df_bpi, df_tech, df_maddy, df_CESFR, df_mina, df_viva, df_siren):
    """üîó Fusionne les DataFrames et remplit les colonnes manquantes"""
    logger.info("üîÑ Fusion des DataFrames...")

    # Fusion progressive
    merged_df = pd.merge(df_bpi, df_tech, on=['nom','description','logo'], how='outer')
    merged_df = pd.merge(merged_df, df_maddy, on=['nom','description','logo'], how='outer')
    merged_df = pd.merge(merged_df, df_CESFR, on=['nom','description','logo'], how='outer')
    merged_df = pd.merge(merged_df, df_mina, on=['nom','description','logo'], how='outer')
    merged_df = pd.merge(merged_df, df_viva, on=['nom','description','logo'], how='outer')
    merged_df = pd.merge(merged_df, df_siren, on=['nom'], how='outer')

    logger.info("‚úÖ Fusion termin√©e.")
    return merged_df


@task
def save_data(df):
    """üíæ Sauvegarde le DataFrame final en CSV"""
    file_path = "output/merged_data.csv"
    df.to_csv(file_path, index=False)
    logger.info(f"‚úÖ Donn√©es sauvegard√©es dans {file_path}")


@flow(name="Prefect Data Pipeline")
def data_pipeline():
    """üöÄ Orchestre le pipeline de transformation des donn√©es"""
    logger.info("üöÄ D√©marrage du pipeline Prefect...")

    # √âtape 1 : Chargement des donn√©es
    df_bpi, df_tech, df_maddy, df_CESFR, df_mina, df_viva, df_siren = load_data()

    # √âtape 2 : D√©ballage de df_mina
    df_mina = unpack_minalogic(df_mina)

    # √âtape 3 : Nettoyage des DataFrames
    df_bpi, df_tech, df_maddy, df_CESFR, df_mina, df_viva, df_siren = clean_data(df_bpi, df_tech, df_maddy, df_CESFR, df_mina, df_viva, df_siren)

    # √âtape 4 : Fusion des DataFrames
    merged_df = merge_data(df_bpi, df_tech, df_maddy, df_CESFR, df_mina, df_viva, df_siren)

    # √âtape 5 : Sauvegarde
    save_data(merged_df)

    logger.info("üèÅ Pipeline termin√© avec succ√®s !")


# üöÄ Ex√©cuter le flow
if __name__ == "__main__":
    data_pipeline()
