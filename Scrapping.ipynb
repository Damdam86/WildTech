{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Site CES 2025\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Configurer Selenium avec WebDriver Manager\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Charger la page principale\n",
    "url = \"https://exhibitors.ces.tech/8_0/#/searchtype/country/search/France/show/all\"\n",
    "driver.get(url)\n",
    "\n",
    "# Attendre que la première liste de cartes charge\n",
    "WebDriverWait(driver, 20).until(\n",
    "    EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'li.js-Card'))\n",
    ")\n",
    "\n",
    "# Affichez un message pour signaler que vous pouvez scroller\n",
    "print(\"Défilez manuellement dans le navigateur pour charger toutes les entreprises.\")\n",
    "print(\"Scrollez jusqu'à ce que plus aucune entreprise ne se charge, puis revenez ici.\")\n",
    "input(\"Appuyez sur Entrée lorsque vous avez terminé le défilement.\")\n",
    "\n",
    "# Extraire les informations des cartes après défilement manuel\n",
    "cards = driver.find_elements(By.CSS_SELECTOR, 'li.js-Card')\n",
    "print(f\"Total d'entreprises affichées : {len(cards)}\")\n",
    "\n",
    "# Liste pour stocker les entreprises\n",
    "exposants = []\n",
    "\n",
    "for index, card in enumerate(cards):\n",
    "    try:\n",
    "        # Récupérer le titre\n",
    "        try:\n",
    "            title_element = card.find_element(By.CSS_SELECTOR, 'h3.card-Title')\n",
    "            name = title_element.text\n",
    "        except:\n",
    "            title_element = card.find_element(By.CSS_SELECTOR, 'a')\n",
    "            name = title_element.text\n",
    "\n",
    "        # Récupérer le lien\n",
    "        try:\n",
    "            link_element = card.find_element(By.CSS_SELECTOR, 'a')  # Modifier ici si nécessaire\n",
    "            link = link_element.get_attribute('href')\n",
    "        except Exception as e:\n",
    "            link = None\n",
    "            print(f\"Erreur lors de l'extraction du lien pour {name}: {e}\")\n",
    "\n",
    "        exposants.append({'Nom': name, 'Lien': link})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur inattendue pour la carte {index + 1} : {e}\")\n",
    "        continue\n",
    "\n",
    "# Vérifiez les entreprises sans lien\n",
    "print(f\"Entreprises sans lien : {[e for e in exposants if e['Lien'] is None]}\")\n",
    "\n",
    "# Extraire les détails pour chaque exposant\n",
    "for exposant in exposants:\n",
    "    try:\n",
    "        if exposant['Lien']:\n",
    "            # Naviguer vers la page entreprise\n",
    "            driver.get(exposant['Lien'])\n",
    "\n",
    "            # Attendre que la page charge les détails\n",
    "            WebDriverWait(driver, 20).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, 'h2.color-brand-02'))\n",
    "            )\n",
    "\n",
    "            # Description\n",
    "            try:\n",
    "                description = driver.find_element(By.CSS_SELECTOR, 'p.js-read-more.animated').text\n",
    "                exposant['Description'] = description if description else \"Non disponible\"\n",
    "            except Exception as e:\n",
    "                exposant['Description'] = \"Non disponible\"\n",
    "                print(f\"Erreur lors de l'extraction de la description pour {exposant['Nom']}: {e}\")\n",
    "\n",
    "            # Catégories de produits\n",
    "            try:\n",
    "                categories = driver.find_elements(By.CSS_SELECTOR, 'div.grid.grid-3-col.grid__centered a')\n",
    "                exposant['Catégories'] = [cat.text for cat in categories] if categories else []\n",
    "            except Exception as e:\n",
    "                exposant['Catégories'] = []\n",
    "                print(f\"Erreur lors de l'extraction des catégories pour {exposant['Nom']}: {e}\")\n",
    "\n",
    "            # Site web\n",
    "            try:\n",
    "                website = driver.find_element(By.CSS_SELECTOR, 'ul.showcase-web-phone a').get_attribute('href')\n",
    "                exposant['Website'] = website if website else \"Non disponible\"\n",
    "            except Exception as e:\n",
    "                exposant['Website'] = \"Non disponible\"\n",
    "                print(f\"Erreur lors de l'extraction du site web pour {exposant['Nom']}: {e}\")\n",
    "\n",
    "            # LinkedIn\n",
    "            try:\n",
    "                linkedin = driver.find_element(By.CSS_SELECTOR, 'div.showcase-social.center.tc a').get_attribute('href')\n",
    "                exposant['LinkedIn'] = linkedin if linkedin else \"Non disponible\"\n",
    "            except Exception as e:\n",
    "                exposant['LinkedIn'] = \"Non disponible\"\n",
    "                print(f\"Erreur lors de l'extraction du LinkedIn pour {exposant['Nom']}: {e}\")\n",
    "\n",
    "            # Adresse\n",
    "            try:\n",
    "                address = driver.find_element(By.CSS_SELECTOR, 'p.showcase-address.tc').text\n",
    "                exposant['Adresse'] = address if address else \"Non disponible\"\n",
    "            except Exception as e:\n",
    "                exposant['Adresse'] = \"Non disponible\"\n",
    "                print(f\"Erreur lors de l'extraction de l'adresse pour {exposant['Nom']}: {e}\")\n",
    "        else:\n",
    "            print(f\"Pas de lien trouvé pour {exposant['Nom']}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'extraction des détails pour {exposant['Nom']} : {e}\")\n",
    "\n",
    "# Fermer le navigateur\n",
    "driver.quit()\n",
    "\n",
    "# Afficher les résultats\n",
    "print(f\"Nombre d'entreprises extraites : {len(exposants)}\")\n",
    "for exposant in exposants[:10]:  # Afficher les 10 premières entreprises pour vérification\n",
    "    print(exposant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exposants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# Exporter les données en CSV\n",
    "csv_filename = \"exposants.csv\"\n",
    "csv_columns = ['Nom', 'Lien', 'Description', 'Catégories', 'Website', 'LinkedIn', 'Adresse']\n",
    "\n",
    "try:\n",
    "    with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "        writer.writeheader()\n",
    "        for exposant in exposants:\n",
    "            # Convertir la liste des catégories en chaîne séparée par des virgules\n",
    "            exposant['Catégories'] = \", \".join(exposant.get('Catégories', []))\n",
    "            writer.writerow(exposant)\n",
    "    print(f\"Les données ont été exportées avec succès dans le fichier '{csv_filename}'.\")\n",
    "except IOError as e:\n",
    "    print(f\"Erreur lors de l'exportation en CSV : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Site CES 2025 - AI World\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Configurer Selenium avec WebDriver Manager\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Charger la page principale\n",
    "url = \"https://exhibitors.ces.tech/8_0/#/searchtype/category/search/191/show/all\"\n",
    "driver.get(url)\n",
    "\n",
    "# Attendre que la première liste de cartes charge\n",
    "WebDriverWait(driver, 20).until(\n",
    "    EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'li.js-Card'))\n",
    ")\n",
    "\n",
    "# Affichez un message pour signaler que vous pouvez scroller\n",
    "print(\"Défilez manuellement dans le navigateur pour charger toutes les entreprises.\")\n",
    "print(\"Scrollez jusqu'à ce que plus aucune entreprise ne se charge, puis revenez ici.\")\n",
    "input(\"Appuyez sur Entrée lorsque vous avez terminé le défilement.\")\n",
    "\n",
    "# Extraire les informations des cartes après défilement manuel\n",
    "cards = driver.find_elements(By.CSS_SELECTOR, 'li.js-Card')\n",
    "print(f\"Total d'entreprises affichées : {len(cards)}\")\n",
    "\n",
    "# Liste pour stocker les entreprises\n",
    "exposants = []\n",
    "\n",
    "for index, card in enumerate(cards):\n",
    "    try:\n",
    "        # Récupérer le titre\n",
    "        try:\n",
    "            title_element = card.find_element(By.CSS_SELECTOR, 'h3.card-Title')\n",
    "            name = title_element.text\n",
    "        except:\n",
    "            title_element = card.find_element(By.CSS_SELECTOR, 'a')\n",
    "            name = title_element.text\n",
    "\n",
    "        # Récupérer le lien\n",
    "        try:\n",
    "            link_element = card.find_element(By.CSS_SELECTOR, 'a')  # Modifier ici si nécessaire\n",
    "            link = link_element.get_attribute('href')\n",
    "        except Exception as e:\n",
    "            link = None\n",
    "            print(f\"Erreur lors de l'extraction du lien pour {name}: {e}\")\n",
    "\n",
    "        exposants.append({'Nom': name, 'Lien': link})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur inattendue pour la carte {index + 1} : {e}\")\n",
    "        continue\n",
    "\n",
    "# Vérifiez les entreprises sans lien\n",
    "print(f\"Entreprises sans lien : {[e for e in exposants if e['Lien'] is None]}\")\n",
    "\n",
    "# Extraire les détails pour chaque exposant\n",
    "for exposant in exposants:\n",
    "    try:\n",
    "        if exposant['Lien']:\n",
    "            # Naviguer vers la page entreprise\n",
    "            driver.get(exposant['Lien'])\n",
    "\n",
    "            # Attendre que la page charge les détails\n",
    "            WebDriverWait(driver, 20).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, 'h2.color-brand-02'))\n",
    "            )\n",
    "\n",
    "            # Description\n",
    "            try:\n",
    "                description = driver.find_element(By.CSS_SELECTOR, 'p.js-read-more.animated').text\n",
    "                exposant['Description'] = description if description else \"Non disponible\"\n",
    "            except Exception as e:\n",
    "                exposant['Description'] = \"Non disponible\"\n",
    "                print(f\"Erreur lors de l'extraction de la description pour {exposant['Nom']}: {e}\")\n",
    "\n",
    "            # Catégories de produits\n",
    "            try:\n",
    "                categories = driver.find_elements(By.CSS_SELECTOR, 'div.grid.grid-3-col.grid__centered a')\n",
    "                exposant['Catégories'] = [cat.text for cat in categories] if categories else []\n",
    "            except Exception as e:\n",
    "                exposant['Catégories'] = []\n",
    "                print(f\"Erreur lors de l'extraction des catégories pour {exposant['Nom']}: {e}\")\n",
    "\n",
    "            # Site web\n",
    "            try:\n",
    "                website = driver.find_element(By.CSS_SELECTOR, 'ul.showcase-web-phone a').get_attribute('href')\n",
    "                exposant['Website'] = website if website else \"Non disponible\"\n",
    "            except Exception as e:\n",
    "                exposant['Website'] = \"Non disponible\"\n",
    "                print(f\"Erreur lors de l'extraction du site web pour {exposant['Nom']}: {e}\")\n",
    "\n",
    "            # LinkedIn\n",
    "            try:\n",
    "                linkedin = driver.find_element(By.CSS_SELECTOR, 'div.showcase-social.center.tc a').get_attribute('href')\n",
    "                exposant['LinkedIn'] = linkedin if linkedin else \"Non disponible\"\n",
    "            except Exception as e:\n",
    "                exposant['LinkedIn'] = \"Non disponible\"\n",
    "                print(f\"Erreur lors de l'extraction du LinkedIn pour {exposant['Nom']}: {e}\")\n",
    "\n",
    "            # Adresse\n",
    "            try:\n",
    "                address = driver.find_element(By.CSS_SELECTOR, 'p.showcase-address.tc').text\n",
    "                exposant['Adresse'] = address if address else \"Non disponible\"\n",
    "            except Exception as e:\n",
    "                exposant['Adresse'] = \"Non disponible\"\n",
    "                print(f\"Erreur lors de l'extraction de l'adresse pour {exposant['Nom']}: {e}\")\n",
    "        else:\n",
    "            print(f\"Pas de lien trouvé pour {exposant['Nom']}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'extraction des détails pour {exposant['Nom']} : {e}\")\n",
    "\n",
    "# Fermer le navigateur\n",
    "driver.quit()\n",
    "\n",
    "# Afficher les résultats\n",
    "print(f\"Nombre d'entreprises extraites : {len(exposants)}\")\n",
    "for exposant in exposants[:10]:  # Afficher les 10 premières entreprises pour vérification\n",
    "    print(exposant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# Exporter les données en CSV\n",
    "csv_filename = \"exposants.csv\"\n",
    "csv_columns = ['Nom', 'Lien', 'Description', 'Catégories', 'Website', 'LinkedIn', 'Adresse']\n",
    "\n",
    "try:\n",
    "    with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "        writer.writeheader()\n",
    "        for exposant in exposants:\n",
    "            # Convertir la liste des catégories en chaîne séparée par des virgules\n",
    "            exposant['Catégories'] = \", \".join(exposant.get('Catégories', []))\n",
    "            writer.writerow(exposant)\n",
    "    print(f\"Les données ont été exportées avec succès dans le fichier '{csv_filename}'.\")\n",
    "except IOError as e:\n",
    "    print(f\"Erreur lors de l'exportation en CSV : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Les pepites tech\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import csv\n",
    "import time\n",
    "\n",
    "# Configurer Selenium avec WebDriver Manager\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Charger la page principale\n",
    "url = \"https://lespepitestech.com/best-of-pepites\"\n",
    "driver.get(url)\n",
    "\n",
    "# Attendre que la première page charge\n",
    "WebDriverWait(driver, 20).until(\n",
    "    EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div.s-e-content'))\n",
    ")\n",
    "\n",
    "# Afficher un message pour naviguer manuellement à la bonne page de départ\n",
    "input(\"Naviguez manuellement vers la page de départ, puis appuyez sur Entrée pour commencer le scraping des pages suivantes.\")\n",
    "\n",
    "# Liste pour stocker les entreprises\n",
    "entreprises = []\n",
    "\n",
    "# Fonction pour scraper les données d'une page\n",
    "def scraper_page():\n",
    "    cards = driver.find_elements(By.CSS_SELECTOR, 'div.s-e-content')\n",
    "    for card in cards:\n",
    "        try:\n",
    "            entreprise = {}\n",
    "\n",
    "            # Nom de l'entreprise\n",
    "            try:\n",
    "                nom = card.find_element(By.CSS_SELECTOR, 'div.s-e-title h3').text\n",
    "                entreprise['Nom'] = nom\n",
    "            except Exception:\n",
    "                entreprise['Nom'] = \"Non disponible\"\n",
    "\n",
    "            # Description de l'entreprise\n",
    "            try:\n",
    "                description = card.find_element(By.CSS_SELECTOR, 'div.s-u-summary').text\n",
    "                entreprise['Description'] = description\n",
    "            except Exception:\n",
    "                entreprise['Description'] = \"Non disponible\"\n",
    "\n",
    "            # Catégories\n",
    "            try:\n",
    "                categories = card.find_elements(By.CSS_SELECTOR, 'div.lpt-dropdown-category span.tag a')\n",
    "                entreprise['Catégories'] = [cat.text for cat in categories]\n",
    "            except Exception:\n",
    "                entreprise['Catégories'] = []\n",
    "\n",
    "            # Votes\n",
    "            try:\n",
    "                votes = card.find_element(By.CSS_SELECTOR, 'div.counter.card-vote .alternate-votes-display').text.strip()\n",
    "                entreprise['Votes'] = votes\n",
    "            except Exception:\n",
    "                entreprise['Votes'] = \"Non disponible\"\n",
    "\n",
    "            # Commentaires\n",
    "            try:\n",
    "                commentaires = card.find_element(By.CSS_SELECTOR, 'div.counter.card-comment').text.strip()\n",
    "                entreprise['Commentaires'] = commentaires\n",
    "            except Exception:\n",
    "                entreprise['Commentaires'] = \"Non disponible\"\n",
    "\n",
    "            # Site Web\n",
    "            try:\n",
    "                site_web = card.find_element(By.CSS_SELECTOR, 'div.s-e-link a').get_attribute('href')\n",
    "                entreprise['Site Web'] = site_web\n",
    "            except Exception:\n",
    "                entreprise['Site Web'] = \"Non disponible\"\n",
    "\n",
    "            # Localisation\n",
    "            try:\n",
    "                localisation = card.find_element(By.CSS_SELECTOR, 'div.card-location a').get_attribute('data-original-title')\n",
    "                entreprise['Localisation'] = localisation\n",
    "            except Exception:\n",
    "                entreprise['Localisation'] = \"Non disponible\"\n",
    "\n",
    "            entreprises.append(entreprise)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de l'extraction des données pour une entreprise : {e}\")\n",
    "            continue\n",
    "\n",
    "# Scraper les données des pages automatiquement\n",
    "while True:\n",
    "    scraper_page()\n",
    "    try:\n",
    "        # Trouver le bouton \"Page suivante\" via le titre ou le texte\n",
    "        next_button = driver.find_element(By.CSS_SELECTOR, 'a[title=\"Aller à la page suivante\"]')\n",
    "        driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "        time.sleep(3)  # Attendre que la nouvelle page charge\n",
    "    except Exception:\n",
    "        print(\"Aucune autre page trouvée. Fin du scraping.\")\n",
    "        break\n",
    "\n",
    "# Fermer le navigateur\n",
    "driver.quit()\n",
    "\n",
    "# Exporter les données en CSV\n",
    "csv_filename = \"pepites_scraped.csv\"\n",
    "csv_columns = ['Nom', 'Description', 'Catégories', 'Votes', 'Commentaires', 'Site Web', 'Localisation']\n",
    "\n",
    "try:\n",
    "    with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "        writer.writeheader()\n",
    "        for entreprise in entreprises:\n",
    "            writer.writerow(entreprise)\n",
    "    print(f\"Les données ont été exportées avec succès dans le fichier '{csv_filename}'.\")\n",
    "except IOError as e:\n",
    "    print(f\"Erreur lors de l'exportation en CSV : {e}\")\n",
    "\n",
    "# Afficher les premières entreprises\n",
    "for entreprise in entreprises[:10]:\n",
    "    print(entreprise)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
